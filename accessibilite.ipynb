{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b0600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import gc\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "from typing import Literal\n",
    "from dataclasses import dataclass\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ec9a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15f9f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelledTensor:\n",
    "    \"\"\"\n",
    "    Classe enveloppe pour un tenseur PyTorch avec des étiquettes explicites pour chaque dimension.\n",
    "\n",
    "    Attributs\n",
    "    ---------\n",
    "    tensor : torch.Tensor\n",
    "        Le tenseur brut.\n",
    "    dim_labels : list[str]\n",
    "        Liste ordonnée des noms des dimensions.\n",
    "    index_to_label : dict[str, list[str]]\n",
    "        Dictionnaire associant à chaque nom de dimension la liste de ses étiquettes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tensor: torch.Tensor, dim_labels: list[str], index_to_label: dict[str, list[str]]):\n",
    "        \"\"\"\n",
    "        Initialise un objet LabelledTensor.\n",
    "\n",
    "        Paramètres\n",
    "        ----------\n",
    "        tensor : torch.Tensor\n",
    "            Le tenseur PyTorch à encapsuler.\n",
    "        dim_labels : list[str]\n",
    "            Les noms des dimensions du tenseur.\n",
    "        index_to_label : dict[str, list[str]]\n",
    "            Les étiquettes associées à chaque dimension.\n",
    "        \"\"\"\n",
    "        self.tensor = tensor\n",
    "        self.dim_labels = dim_labels\n",
    "        self.index_to_label = index_to_label\n",
    "\n",
    "    def to(self, device):\n",
    "        \"\"\"\n",
    "        Déplace le tenseur vers le périphérique spécifié (CPU ou GPU).\n",
    "\n",
    "        Paramètre\n",
    "        ---------\n",
    "        device : str\n",
    "            'cpu' ou 'cuda' (ou tout autre périphérique reconnu par PyTorch).\n",
    "        \n",
    "        Retourne\n",
    "        --------\n",
    "        self : LabelledTensor\n",
    "            L'objet lui-même après déplacement.\n",
    "        \"\"\"\n",
    "        self.tensor = self.tensor.to(device)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Représentation courte de l'objet pour un affichage rapide.\n",
    "        \"\"\"\n",
    "        return f\"LabelledTensor(shape={self.tensor.shape}, dims={self.dim_labels})\"\n",
    "\n",
    "    \n",
    "    def display(self, max_elements: int = 100, filters: dict[str, list[str]] = None) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Affiche une vue lisible du tenseur sous forme d'un DataFrame Polars avec les étiquettes,\n",
    "        en permettant un filtrage rapide par labels.\n",
    "\n",
    "        Paramètres\n",
    "        ----------\n",
    "        max_elements : int, par défaut 100\n",
    "            Nombre maximal d'éléments à afficher.\n",
    "        filters : dict[str, list[str]], optional\n",
    "            Dictionnaire {nom_dimension: [liste de labels à afficher]}.\n",
    "            Permet de restreindre l'affichage à certaines étiquettes.\n",
    "\n",
    "        Retour\n",
    "        ------\n",
    "        pl.DataFrame\n",
    "            Un DataFrame Polars avec les étiquettes et les valeurs du tenseur.\n",
    "        \"\"\"\n",
    "        flat_indices = torch.nonzero(self.tensor, as_tuple=False)\n",
    "\n",
    "        # Si des filtres sont fournis\n",
    "        if filters:\n",
    "            mask = torch.ones(flat_indices.size(0), dtype=torch.bool)\n",
    "\n",
    "            for dim_name, accepted_labels in filters.items():\n",
    "                if dim_name not in self.dim_labels:\n",
    "                    raise ValueError(f\"Dimension '{dim_name}' inconnue.\")\n",
    "\n",
    "                dim_idx = self.dim_labels.index(dim_name)\n",
    "                label_to_index = self.index_to_label[dim_name]\n",
    "\n",
    "                try:\n",
    "                    accepted_set = set(label_to_index.index(label) for label in accepted_labels)\n",
    "                except ValueError as e:\n",
    "                    raise ValueError(f\"Un des labels fournis dans '{dim_name}' est invalide.\") from e\n",
    "\n",
    "                # Utilisation de torch.isin pour un filtrage rapide\n",
    "                dim_values = flat_indices[:, dim_idx]\n",
    "                accepted_tensor = torch.tensor(list(accepted_set), device=dim_values.device)\n",
    "                mask &= torch.isin(dim_values, accepted_tensor)\n",
    "\n",
    "            flat_indices = flat_indices[mask]\n",
    "\n",
    "        # Limiter l'affichage\n",
    "        if flat_indices.size(0) > max_elements:\n",
    "            print(f\"[INFO] Affichage des {max_elements} premiers éléments sur {flat_indices.size(0)} non nuls.\")\n",
    "            flat_indices = flat_indices[:max_elements]\n",
    "\n",
    "        values = self.tensor[tuple(flat_indices.T)].cpu().tolist()\n",
    "\n",
    "        # Récupération rapide des étiquettes\n",
    "        records = []\n",
    "        for i in range(flat_indices.size(0)):\n",
    "            labels = [\n",
    "                self.index_to_label[dim][flat_indices[i, j].item()]\n",
    "                for j, dim in enumerate(self.dim_labels)\n",
    "            ]\n",
    "            records.append((*labels, values[i]))\n",
    "\n",
    "        columns = self.dim_labels + [\"valeur\"]\n",
    "        return pl.DataFrame(records, schema=columns)\n",
    "    \n",
    "\n",
    "    def to_dataframe(\n",
    "        self,\n",
    "        index_dim: str,\n",
    "        column_dim: str | None = None,\n",
    "        index_name: str | None = None,\n",
    "        value_name: str = \"valeur\",\n",
    "        fixed_dims: dict[str, str] = None,\n",
    "    ) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Convertit un LabelledTensor (1D, 2D ou 3D) en DataFrame Polars.\n",
    "\n",
    "        Si 3D, nécessite de fixer les dimensions supplémentaires avec `fixed_dims`.\n",
    "\n",
    "        Paramètres\n",
    "        ----------\n",
    "        index_dim : str\n",
    "            Nom de la dimension pour les lignes.\n",
    "        column_dim : str, optional\n",
    "            Nom de la dimension pour les colonnes (requis pour 2D ou 3D).\n",
    "        index_name : str, optional\n",
    "            Nom personnalisé de la colonne d'index.\n",
    "        value_name : str\n",
    "            Nom de la colonne des valeurs (pour tenseurs 1D).\n",
    "        fixed_dims : dict[str, str]\n",
    "            Pour tenseurs 3D : dictionnaire {nom_dim: label_valeur} pour fixer la dimension restante.\n",
    "\n",
    "        Retour\n",
    "        ------\n",
    "        pl.DataFrame\n",
    "        \"\"\"\n",
    "        if index_dim not in self.dim_labels:\n",
    "            raise ValueError(f\"{index_dim} n'est pas une dimension valide.\")\n",
    "\n",
    "        if self.tensor.ndim == 1:\n",
    "            if column_dim is not None:\n",
    "                raise ValueError(\"column_dim doit être None pour les tenseurs 1D.\")\n",
    "            labels = self.index_to_label[index_dim]\n",
    "            values = self.tensor.cpu().numpy().tolist()\n",
    "            return pl.DataFrame({\n",
    "                index_name or index_dim: labels,\n",
    "                value_name: values\n",
    "            })\n",
    "\n",
    "        if self.tensor.ndim == 2:\n",
    "            if column_dim is None:\n",
    "                raise ValueError(\"column_dim est requis pour les tenseurs 2D.\")\n",
    "            if column_dim not in self.dim_labels:\n",
    "                raise ValueError(f\"{column_dim} n'est pas une dimension valide.\")\n",
    "            row_idx = self.dim_labels.index(index_dim)\n",
    "            col_idx = self.dim_labels.index(column_dim)\n",
    "\n",
    "            tensor = self.tensor.permute(row_idx, col_idx) if (row_idx, col_idx) != (0, 1) else self.tensor\n",
    "            row_labels = self.index_to_label[index_dim]\n",
    "            col_labels = self.index_to_label[column_dim]\n",
    "            values_np = tensor.cpu().numpy()\n",
    "\n",
    "            df_dict = {index_name or index_dim: row_labels}\n",
    "            for j, col in enumerate(col_labels):\n",
    "                df_dict[col] = values_np[:, j]\n",
    "\n",
    "            return pl.DataFrame(df_dict)\n",
    "\n",
    "        if self.tensor.ndim == 3:\n",
    "            if fixed_dims is None or len(fixed_dims) != 1:\n",
    "                raise ValueError(\"Pour les tenseurs 3D, il faut fixer une dimension avec `fixed_dims={dim: label}`.\")\n",
    "\n",
    "            fixed_dim_name, fixed_label = next(iter(fixed_dims.items()))\n",
    "\n",
    "            if fixed_dim_name not in self.dim_labels:\n",
    "                raise ValueError(f\"Dimension '{fixed_dim_name}' non trouvée dans {self.dim_labels}.\")\n",
    "\n",
    "            dim_indices = {dim: self.dim_labels.index(dim) for dim in self.dim_labels}\n",
    "            fixed_idx = self.index_to_label[fixed_dim_name].index(fixed_label)\n",
    "\n",
    "            # Réorganiser pour amener la dimension fixée en dernière position, puis découper (ou extraire)\n",
    "            perm = [dim_indices[index_dim], dim_indices[column_dim], dim_indices[fixed_dim_name]]\n",
    "            tensor_perm = self.tensor.permute(perm)  # [i, j, t]\n",
    "            tensor_2d = tensor_perm[:, :, fixed_idx]  # fix t\n",
    "\n",
    "            # Préparer le DataFrame\n",
    "            row_labels = self.index_to_label[index_dim]\n",
    "            col_labels = self.index_to_label[column_dim]\n",
    "            values_np = tensor_2d.cpu().numpy()\n",
    "\n",
    "            df_dict = {index_name or index_dim: row_labels}\n",
    "            for j, col in enumerate(col_labels):\n",
    "                df_dict[col] = values_np[:, j]\n",
    "\n",
    "            return pl.DataFrame(df_dict)\n",
    "\n",
    "        raise ValueError(\"Seuls les tenseurs 1D, 2D ou 3D sont pris en charge.\")\n",
    "    \n",
    "\n",
    "    def _align_and_apply(self, other, op):\n",
    "        \"\"\"\n",
    "        Aligne deux LabelledTensors sur leurs dimensions et labels, \n",
    "        puis applique une opération élément par élément.\n",
    "\n",
    "        Paramètres\n",
    "        ----------\n",
    "        other : LabelledTensor\n",
    "            Le deuxième tenseur à utiliser dans l'opération.\n",
    "        op : function\n",
    "            Une fonction PyTorch à appliquer, comme torch.add, torch.mul, etc.\n",
    "\n",
    "        Retour\n",
    "        ------\n",
    "        LabelledTensor\n",
    "            Le résultat de l'opération entre les deux LabelledTensors, \n",
    "            avec conservation des métadonnées.\n",
    "\n",
    "        Exceptions\n",
    "        ----------\n",
    "        TypeError : si `other` n'est pas un LabelledTensor.\n",
    "        ValueError : si les dimensions ou les étiquettes ne correspondent pas parfaitement.\n",
    "        \"\"\"\n",
    "        # Vérifie que l'autre objet est un LabelledTensor\n",
    "        if not isinstance(other, LabelledTensor):\n",
    "            raise TypeError(\"Opérations valides uniquement entre deux LabelledTensors.\")\n",
    "\n",
    "        # Vérifie que l'ordre et les noms des dimensions correspondent\n",
    "        if self.dim_labels != other.dim_labels:\n",
    "            raise ValueError(\"Les dimensions doivent être dans le même ordre.\")\n",
    "\n",
    "        # Vérifie que les étiquettes des dimensions correspondent une à une\n",
    "        for dim in self.dim_labels:\n",
    "            if self.index_to_label[dim] != other.index_to_label[dim]:\n",
    "                raise ValueError(f\"Les labels de la dimension '{dim}' ne correspondent pas.\")\n",
    "\n",
    "        # Applique l'opération élément par élément entre les tenseurs bruts\n",
    "        result_tensor = op(self.tensor, other.tensor)\n",
    "\n",
    "        # Retourne un nouveau LabelledTensor avec les mêmes métadonnées\n",
    "        return LabelledTensor(result_tensor, self.dim_labels, self.index_to_label.copy())\n",
    "\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        \"\"\"\n",
    "        Division élément par élément entre deux LabelledTensors alignés.\n",
    "\n",
    "        Paramètres\n",
    "        ----------\n",
    "        other : LabelledTensor\n",
    "\n",
    "        Retour\n",
    "        ------\n",
    "        LabelledTensor\n",
    "        \"\"\"\n",
    "        return self._align_and_apply(other, torch.div)\n",
    "\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        \"\"\"\n",
    "        Multiplication élément par élément entre deux LabelledTensors alignés.\n",
    "\n",
    "        Paramètres\n",
    "        ----------\n",
    "        other : LabelledTensor\n",
    "\n",
    "        Retour\n",
    "        ------\n",
    "        LabelledTensor\n",
    "        \"\"\"\n",
    "        return self._align_and_apply(other, torch.mul)\n",
    "\n",
    "\n",
    "    def __add__(self, other):\n",
    "        \"\"\"\n",
    "        Addition élément par élément entre deux LabelledTensors alignés.\n",
    "\n",
    "        Paramètres\n",
    "        ----------\n",
    "        other : LabelledTensor\n",
    "\n",
    "        Retour\n",
    "        ------\n",
    "        LabelledTensor\n",
    "        \"\"\"\n",
    "        return self._align_and_apply(other, torch.add)\n",
    "\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        \"\"\"\n",
    "        Soustraction élément par élément entre deux LabelledTensors alignés.\n",
    "\n",
    "        Paramètres\n",
    "        ----------\n",
    "        other : LabelledTensor\n",
    "\n",
    "        Retour\n",
    "        ------\n",
    "        LabelledTensor\n",
    "        \"\"\"\n",
    "        return self._align_and_apply(other, torch.sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3ce490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_symmetric_matrix(df: pl.DataFrame, device=\"cpu\") -> LabelledTensor:\n",
    "    \"\"\"\n",
    "    Construit une matrice symétrique des temps de parcours à partir d'un DataFrame triangle supérieur.\n",
    "\n",
    "    Paramètres :\n",
    "    ------------\n",
    "    df : pl.DataFrame\n",
    "        Doit contenir les colonnes \"Idloc_start\", \"Idloc_end\", \"temps_parcours\".\n",
    "    device : str\n",
    "        'cpu' ou 'cuda' selon l'appareil souhaité.\n",
    "\n",
    "    Retour :\n",
    "    --------\n",
    "    LabelledTensor\n",
    "        Matrice [i, j] symétrique, avec labels.\n",
    "    \"\"\"\n",
    "    # Étape 1 : identifiants uniques ordonnés\n",
    "    unique_locs = pl.concat([df[\"Idloc_start\"], df[\"Idloc_end\"]]).unique().sort()\n",
    "    # print(unique_locs)\n",
    "    idx_to_id = unique_locs.to_list()\n",
    "    id_to_idx = {idloc: idx for idx, idloc in enumerate(idx_to_id)}\n",
    "    n = len(idx_to_id)\n",
    "\n",
    "    # Étape 2 : conversion en indices numpy \n",
    "    i_idx = df[\"Idloc_start\"].to_numpy()\n",
    "    j_idx = df[\"Idloc_end\"].to_numpy()\n",
    "    values = df[\"temps_parcours\"].to_numpy()\n",
    "\n",
    "    # Étape 3 : mapping des ID vers index\n",
    "    i_indices = np.vectorize(id_to_idx.get)(i_idx)\n",
    "    j_indices = np.vectorize(id_to_idx.get)(j_idx)\n",
    "\n",
    "    # Étape 4 : remplissage de la matrice via vecteurs\n",
    "    T = torch.full((n, n), float(\"inf\"), dtype=torch.float32, device=device)\n",
    "    indices = torch.tensor(np.stack([i_indices, j_indices]), device=device)\n",
    "    distances = torch.tensor(values, dtype=torch.float32, device=device)\n",
    "\n",
    "    # Triangle supérieur\n",
    "    T[indices[0], indices[1]] = distances\n",
    "    # Symétrie\n",
    "    T[indices[1], indices[0]] = distances\n",
    "    # Diagonale\n",
    "    T.fill_diagonal_(0.0)\n",
    "\n",
    "    return LabelledTensor(T, [\"i\", \"j\"], {\"i\": idx_to_id, \"j\": idx_to_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "766d817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_population_tensor(\n",
    "    df_pop: pl.DataFrame, \n",
    "    idloc_order: list[str], \n",
    "    device: str = \"cpu\", \n",
    "    normalization: str = \"none\"\n",
    ") -> LabelledTensor:\n",
    "    \"\"\"\n",
    "    Crée un vecteur de population ordonné selon idloc, avec option de normalisation.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    df_pop : pl.DataFrame\n",
    "        Contient les colonnes \"Idloc\" et \"taille_population\".\n",
    "    idloc_order : list[str]\n",
    "        Ordre des localités à respecter.\n",
    "    device : str, default=\"cpu\"\n",
    "        Appareil cible (ex. \"cpu\" ou \"cuda\").\n",
    "    normalization : str, default=\"none\"\n",
    "        Méthode de normalisation à appliquer :\n",
    "            - \"none\"   : pas de normalisation.\n",
    "            - \"minmax\" : (x - min) / (max - min), borné entre 0 et 1.\n",
    "            - \"zscore\" : (x - mean) / std, puis rendu positif (shifté par +|min| si nécessaire).\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    LabelledTensor\n",
    "        Vecteur [i] des tailles de population (normalisées ou non).\n",
    "    \"\"\"\n",
    "    # Extraction des valeurs de population selon l'ordre fourni\n",
    "    raw_values = [\n",
    "        df_pop.filter(pl.col(\"Idloc\") == loc)[\"taille_population\"][0]\n",
    "        for loc in idloc_order\n",
    "    ]\n",
    "    pop = torch.tensor(raw_values, dtype=torch.float32, device=device)\n",
    "\n",
    "    # Application d'une normalisation si demandée\n",
    "    if normalization == \"minmax\":\n",
    "        min_val = pop.min()\n",
    "        max_val = pop.max()\n",
    "        if max_val > min_val:\n",
    "            pop = (pop - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            pop = torch.zeros_like(pop)  # évite division par 0\n",
    "\n",
    "    elif normalization == \"zscore\":\n",
    "        mean = pop.mean()\n",
    "        std = pop.std()\n",
    "        if std > 0:\n",
    "            pop = (pop - mean) / std\n",
    "        else:\n",
    "            pop = pop - mean  # pas de std → centré uniquement\n",
    "        # Décalage pour garantir positivité\n",
    "        min_val = pop.min()\n",
    "        if min_val < 0:\n",
    "            pop = pop + (-min_val)\n",
    "\n",
    "    elif normalization != \"none\":\n",
    "        raise ValueError(f\"Unknown normalization method: {normalization}\")\n",
    "\n",
    "    return LabelledTensor(pop, [\"i\"], {\"i\": idloc_order})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edf738d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_infrastructure_tensor(df: pl.DataFrame, device=\"cpu\") -> LabelledTensor:\n",
    "    \"\"\"\n",
    "    Construit un tenseur D[i, t] représentant les infrastructures disponibles.\n",
    "\n",
    "    Les noms des colonnes encodent le secteur (k) dans leurs deux premiers caractères.\n",
    "\n",
    "    Paramètres :\n",
    "    ------------\n",
    "    df : pl.DataFrame\n",
    "        Doit contenir la colonne \"idloc\" et des colonnes de sous-secteurs.\n",
    "    device : str\n",
    "        Appareil.\n",
    "\n",
    "    Retour :\n",
    "    --------\n",
    "    LabelledTensor\n",
    "        Tenseur [i, t] : localité × sous-secteur.\n",
    "    \"\"\"\n",
    "    idlocs = df[\"idloc\"].to_list()\n",
    "    df_data = df.drop(\"idloc\")\n",
    "    sous_secteurs = df_data.columns\n",
    "\n",
    "    D = torch.tensor(\n",
    "        df_data.to_numpy(),\n",
    "        dtype=torch.float32,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    return LabelledTensor(D, [\"i\", \"t\"], {\n",
    "        \"i\": idlocs,\n",
    "        \"t\": sous_secteurs\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf47d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_infra_tensor(infra_tensor: LabelledTensor, prefix: str | list[str] = None) -> LabelledTensor:\n",
    "    \"\"\"\n",
    "    Sélectionne les colonnes t du tenseur S[i, t] correspondant à un ou plusieurs préfixes.\n",
    "    Le tenseur S[i, t] représente les infrastructures par type (t) et par localité (i).\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    infra_tensor: LabelledTensor [i, t]\n",
    "        Tenseur contenant les infrastructures par type.\n",
    "    prefix : str ou list[str], optionnel\n",
    "        Préfixe ou liste de préfixes à filtrer sur l'axe t.\n",
    "        Si None, toutes les colonnes sont conservées.\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    LabelledTensor [i, t]\n",
    "        Tenseur filtré.\n",
    "    \"\"\"\n",
    "    tensor = infra_tensor.tensor\n",
    "    labels_t = infra_tensor.index_to_label[\"t\"]\n",
    "    prefix = [prefix] if isinstance(prefix, str) else prefix\n",
    "\n",
    "    if prefix is not None:\n",
    "        keep = [i for i, label in enumerate(labels_t) if any(label.startswith(p) for p in prefix)]\n",
    "        tensor = tensor[:, keep]\n",
    "        labels_t = [labels_t[i] for i in keep]\n",
    "\n",
    "    return LabelledTensor(tensor.clone(), infra_tensor.dim_labels, {\n",
    "        \"i\": infra_tensor.index_to_label[\"i\"],\n",
    "        \"t\": labels_t\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4f98797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_theoretical_infra_tensor(\n",
    "    infra_tensor: LabelledTensor,\n",
    "    population_tensor: LabelledTensor,\n",
    "    normalization_rules: dict[str, float] = None,\n",
    "    default_ratio: float = 1.0\n",
    ") -> LabelledTensor:\n",
    "    \"\"\"\n",
    "    Calcule le nombre théorique d'infrastructures nécessaires par localité et type.\n",
    "\n",
    "    Pour chaque type t, on suppose qu'une infrastructure est nécessaire pour `normalization_rules[t]` habitants.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    infra_tensor : LabelledTensor [i, t]\n",
    "        Nombre d'infrastructures observées par localité (i) et secteur (t).\n",
    "    population : LabelledTensor [i]\n",
    "        Population par localité.\n",
    "    normalization_rules : dict[str, float], optionnel\n",
    "        Règles de normalisation par préfixe de t (ex : {'S': 3000}).\n",
    "    default_ratio : float, optionnel\n",
    "        Ratio par défaut si aucune règle ne correspond.\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    LabelledTensor [i, t]\n",
    "        Nombre d'infrastructures théoriques.\n",
    "    \"\"\"\n",
    "    device = infra_tensor.tensor.device\n",
    "    pop = population_tensor.tensor.view(-1, 1).to(dtype=torch.float32, device=device)\n",
    "\n",
    "    labels_t = infra_tensor.index_to_label[\"t\"]\n",
    "\n",
    "    if normalization_rules is None:\n",
    "        factors = torch.full((1, len(labels_t)), default_ratio, dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        factors = []\n",
    "        for t in labels_t:\n",
    "            factor = next((v for k, v in normalization_rules.items() if t.startswith(k)), default_ratio)\n",
    "            factors.append(factor)\n",
    "        factors = torch.tensor(factors, dtype=torch.float32, device=device).view(1, -1)\n",
    "\n",
    "    S_theoretical = pop / factors  # [i, t]\n",
    "\n",
    "    return LabelledTensor(S_theoretical, [\"i\", \"t\"], {\n",
    "        \"i\": infra_tensor.index_to_label[\"i\"],\n",
    "        \"t\": labels_t\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c567d02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_tensor(distance_tensor: LabelledTensor, infra_tensor: LabelledTensor, device=\"cpu\") -> LabelledTensor:\n",
    "    \"\"\"\n",
    "    Construit un tenseur D[i, j, t] des distances inter localités [i, j], ne conservant \n",
    "    les distances que vers les localités j possédant une infrastructure de type t.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    distance_tensor : LabelledTensor [i, j]\n",
    "        Distances entre localités i et j.\n",
    "    infra_tensor : LabelledTensor [j, t]\n",
    "        Disponibilité des infrastructures à chaque localité j.\n",
    "    device : str\n",
    "        Périphérique ('cpu' ou 'cuda').\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    LabelledTensor [i, j, t]\n",
    "        Distances pondérées.\n",
    "    \"\"\"\n",
    "    dist = distance_tensor.tensor.to(device)\n",
    "    infra_mask = (infra_tensor.tensor.to(device) > 0).float()\n",
    "\n",
    "    dist_3d = dist.unsqueeze(-1)          # [i, j, 1]\n",
    "    mask_3d = infra_mask.unsqueeze(0)     # [1, j, t]\n",
    "\n",
    "    D_tensor = dist_3d * mask_3d          # [i, j, t]\n",
    "\n",
    "    return LabelledTensor(D_tensor, [\"i\", \"j\", \"t\"], {\n",
    "        \"i\": distance_tensor.index_to_label[\"i\"],\n",
    "        \"j\": distance_tensor.index_to_label[\"j\"],\n",
    "        \"t\": infra_tensor.index_to_label[\"t\"]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6e6f37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_max_distance(distance_tensor: LabelledTensor) -> LabelledTensor:\n",
    "    \"\"\"\n",
    "    Calcule Dmax[t] = max_ij D[i, j, t], soit la distance maximale observée par type.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    distance_tensor : LabelledTensor [i, j, t]\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    LabelledTensor [t]\n",
    "    \"\"\"\n",
    "    distance_max = distance_tensor.tensor.amax(dim=(0, 1))\n",
    "    return LabelledTensor(distance_max, [\"t\"], \n",
    "                          {\"t\": distance_tensor.index_to_label[\"t\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da846380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_distance_tensor(distance_tensor: LabelledTensor, distance_max: LabelledTensor) -> LabelledTensor:\n",
    "    \"\"\"\n",
    "    Normalise chaque distance_tensor[i, j, t] par la distance maximale distance_max[t].\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    distance_tensor : LabelledTensor [i, j, t]\n",
    "    distance_max : LabelledTensor [t]\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    LabelledTensor [i, j, t]\n",
    "    \"\"\"\n",
    "    D_norm = distance_tensor.tensor / distance_max.tensor.view(1, 1, -1)\n",
    "    return LabelledTensor(D_norm, distance_tensor.dim_labels, \n",
    "                          distance_tensor.index_to_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "781cc39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_exponential_decay(distance_tensor: LabelledTensor) -> LabelledTensor:\n",
    "    \"\"\"\n",
    "    Applique une fonction de décroissance sur D[i, j, t] :\n",
    "        f(x) = (exp(-0.5 * x) - exp(-0.5)) / (1 - exp(-0.5))\n",
    "\n",
    "    Paramètre\n",
    "    ---------\n",
    "    distance_tensor : LabelledTensor [i, j, t]\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    LabelledTensor [i, j, t]\n",
    "        Tenseur transformé.\n",
    "    \"\"\"\n",
    "    x = distance_tensor.tensor\n",
    "    base = math.exp(-0.5)\n",
    "    denom = 1.0 - base\n",
    "\n",
    "    result = x.clone()\n",
    "    result.mul_(-0.5).exp_().sub_(base).div_(denom)\n",
    "\n",
    "    return LabelledTensor(result, distance_tensor.dim_labels,\n",
    "                          distance_tensor.index_to_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca07a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_infra(distance_tensor: LabelledTensor, infra_tensor: LabelledTensor, restrict: bool = True) -> LabelledTensor:\n",
    "    \"\"\"\n",
    "    Met à zéro les distances D[i, j, t] là où l'infrastructure [j, t] est absente.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    distance_tensor : LabelledTensor [i, j, t]\n",
    "    infra_tensor : LabelledTensor [j, t]\n",
    "    restrict : bool\n",
    "        Si False, retourne D inchangé.\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    LabelledTensor [i, j, t]\n",
    "    \"\"\"\n",
    "    if not restrict:\n",
    "        return distance_tensor\n",
    "\n",
    "    mask = (infra_tensor.tensor > 0).float().unsqueeze(0)  # [1, j, t]\n",
    "    D_masked = distance_tensor.tensor * mask\n",
    "\n",
    "    return LabelledTensor(D_masked, distance_tensor.dim_labels, \n",
    "                          distance_tensor.index_to_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0a1ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_sum(\n",
    "    population_tensor: LabelledTensor,\n",
    "    distance_tensor: LabelledTensor,\n",
    "    apply_inverse: bool = True,\n",
    "    transform: str = None,\n",
    "    a: float = 1.0,\n",
    "    b: float = 0.0,\n",
    "    eps: float = 1e-8\n",
    ") -> LabelledTensor:\n",
    "    \"\"\"\n",
    "    Calcule SOMME[j, t] = ∑_i P[i] * D[i, j, t], avec transformations possibles sur P.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    population_tensor : LabelledTensor [i]\n",
    "        Poids de chaque localité i (peut être transformé).\n",
    "    distance_tensor : LabelledTensor [i, j, t]\n",
    "        Tenseur à pondérer.\n",
    "    apply_inverse : bool, default=True\n",
    "        Si True, retourne 1 / SOMME[j, t], avec 0 si somme == 0.\n",
    "    transform : Optional[str]\n",
    "        Transformation à appliquer sur la population :\n",
    "        - \"log\"        : ln(x + eps)\n",
    "        - \"linear\"     : a * x + b\n",
    "        - \"logaffine\"  : a * ln(x + eps) + b\n",
    "        - None         : pas de transformation\n",
    "    a : float\n",
    "        Coefficient multiplicatif dans la transformation.\n",
    "    b : float\n",
    "        Terme constant dans la transformation.\n",
    "    eps : float\n",
    "        Valeur pour éviter log(0).\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    LabelledTensor [j, t]\n",
    "        Tenseur pondéré (ou son inverse sécurisé).\n",
    "    \"\"\"\n",
    "    pop = population_tensor.tensor\n",
    "\n",
    "    # Transformation de la population si précisé\n",
    "    if transform == \"log\":\n",
    "        pop = torch.log(pop + eps)\n",
    "    elif transform == \"linear\":\n",
    "        pop = a * pop + b\n",
    "    elif transform == \"logaffine\":\n",
    "        pop = a * torch.log(pop + eps) + b\n",
    "\n",
    "    # Calcul pondéré\n",
    "    weighted = pop.view(-1, 1, 1) * distance_tensor.tensor  # [i, j, t]\n",
    "    summed = weighted.sum(dim=0)  # [j, t]\n",
    "\n",
    "    # Inversion sécurisée\n",
    "    if apply_inverse:\n",
    "        summed = torch.where(summed != 0, 1.0 / summed, torch.zeros_like(summed))\n",
    "\n",
    "    return LabelledTensor(summed, [\"j\", \"t\"], {\n",
    "        \"j\": distance_tensor.index_to_label[\"j\"],\n",
    "        \"t\": distance_tensor.index_to_label[\"t\"]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebe82f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_product(infra_tensor: LabelledTensor,\n",
    "                             distance_tensor: LabelledTensor) -> LabelledTensor:\n",
    "    \"\"\"\n",
    "    Calcule PRODUIT[i, j, t] = S[j, t] * D[i, j, t]².\n",
    "\n",
    "    Pondération appliquée colonne par colonne (j), pour chaque type t.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    S : LabelledTensor [j, t]\n",
    "    D : LabelledTensor [i, j, t]\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    LabelledTensor [i, j, t]\n",
    "    \"\"\"\n",
    "    D_squared = distance_tensor.tensor.square()\n",
    "    S_exp = infra_tensor.tensor.unsqueeze(0)  # [1, j, t]\n",
    "    produit = D_squared * S_exp\n",
    "\n",
    "    return LabelledTensor(produit, distance_tensor.dim_labels,\n",
    "                          distance_tensor.index_to_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85aa3d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_access_index(\n",
    "    produit: LabelledTensor,\n",
    "    inv_sum: LabelledTensor\n",
    ") -> LabelledTensor:\n",
    "    \"\"\"\n",
    "    Calcule ACCESS[i, t] = ∑_j PRODUIT[i, j, t] * INV_SUM[j, t]\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    produit : LabelledTensor [i, j, t]\n",
    "        Tenseur produit pondéré.\n",
    "    inv_sum : LabelledTensor [j, t]\n",
    "        Inverse sécurisé des pondérations (1 / SOMME[j, t]).\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    LabelledTensor [i, t]\n",
    "    \"\"\"\n",
    "    weighted = produit.tensor * inv_sum.tensor.unsqueeze(0)\n",
    "    access = weighted.sum(dim=1)\n",
    "\n",
    "    return LabelledTensor(access, [\"i\", \"t\"], {\n",
    "        \"i\": produit.index_to_label[\"i\"],\n",
    "        \"t\": produit.index_to_label[\"t\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cb98ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_matrix(path_dt: str,\n",
    "                path_infra: str,\n",
    "                path_pop: str,\n",
    "                device: str = \"cuda\") -> tuple[LabelledTensor, LabelledTensor, LabelledTensor]:\n",
    "    \"\"\"\n",
    "    Charge et construit les matrices LabelledTensor nécessaires au calcul d'accessibilité :\n",
    "    - Matrice des distances symétrique [i, j]\n",
    "    - Tenseur des infrastructures [i, t]\n",
    "    - Vecteur de population [i]\n",
    "\n",
    "    Paramètres :\n",
    "    ------------\n",
    "    path_dt : str\n",
    "        Chemin vers le fichier Parquet contenant les temps de parcours (triangle supérieur).\n",
    "    path_infra : str\n",
    "        Chemin vers le fichier Parquet contenant les infrastructures.\n",
    "    path_pop : str\n",
    "        Chemin vers le fichier Parquet contenant les populations.\n",
    "    device : str\n",
    "        Périphérique (\"cpu\" ou \"cuda\").\n",
    "\n",
    "    Retour :\n",
    "    --------\n",
    "    tuple[LabelledTensor, LabelledTensor, LabelledTensor]\n",
    "        distance_tensor  : Matrice des temps de parcours [i, j]\n",
    "        infra_tensor     : Tenseur des infrastructures [i, t]\n",
    "        population_tensor: Vecteur des populations [i]\n",
    "    \"\"\"\n",
    "    # Lecture des fichiers parquet\n",
    "    distance = pl.read_parquet(path_dt)\n",
    "    infrastructures = pl.read_parquet(path_infra)\n",
    "    population = pl.read_parquet(path_pop)\n",
    "\n",
    "    # Construction des matrices\n",
    "    distance_tensor = create_symmetric_matrix(distance, device=device)\n",
    "    infra_tensor = create_infrastructure_tensor(infrastructures, device=device)\n",
    "    population_tensor = create_population_tensor(population, population[\"Idloc\"].to_list(),\n",
    "                                                 device=device)\n",
    "\n",
    "    return distance_tensor, infra_tensor, population_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31850f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dt = r\"C:\\Users\\e_koffie\\Documents\\IAI_Project\\SIMULATIONS\\Data\\dt_matrix_ligne_VF.parquet\"\n",
    "path_infra = r\"C:\\Users\\e_koffie\\Documents\\IAI_Project\\SIMULATIONS\\Data\\infrastructure_matrix_VF.parquet\"\n",
    "path_pop = r\"C:\\Users\\e_koffie\\Documents\\IAI_Project\\SIMULATIONS\\Data\\population_matrix.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc2b9b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_tensor, infra_tensor, population_tensor = load_matrix(path_dt, path_infra, \n",
    "                                                               path_pop, device=\"cuda\")\n",
    "\n",
    "infra_tensor = compute_infra_tensor(infra_tensor=infra_tensor, \n",
    "                         prefix=[\"06\"])\n",
    "infra_tensor_th = compute_theoretical_infra_tensor(infra_tensor=infra_tensor,\n",
    "                                        population_tensor=population_tensor,\n",
    "                                        default_ratio=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72d3e227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_access_formula(\n",
    "    distance_tensor: LabelledTensor,\n",
    "    population_tensor: LabelledTensor,\n",
    "    infra_tensor: LabelledTensor,\n",
    "    device: str = \"cpu\"\n",
    ") -> LabelledTensor:\n",
    "    \"\"\"\n",
    "    Calcule l'indice final d'accessibilité pour chaque zone et chaque type d'infrastructure.\n",
    "\n",
    "    Ce calcul suit les étapes suivantes :\n",
    "    1. Génère D[i, j, t] à partir des distances et de la présence d'infrastructure.\n",
    "    2. Normalise D par type t.\n",
    "    3. Applique une fonction de décroissance exponentielle.\n",
    "    4. Restreint les distances aux seules zones équipées.\n",
    "    5. Calcule un dénominateur : somme pondérée des distances selon la population.\n",
    "    6. Calcule un numérateur : produit pondéré des distances au carré selon l'offre.\n",
    "    7. Calcule l'indice final ACCESS[i, t].\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    distance_tensor : LabelledTensor [i, j]\n",
    "        Matrice des distances entre localités.\n",
    "    population_tensor : LabelledTensor [i]\n",
    "        Population par localité.\n",
    "    infra_tensor : LabelledTensor [j, t]\n",
    "        Présence d'infrastructures par localité et type.\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    LabelledTensor [i, t]\n",
    "        Indice d'ccessibilité final.\n",
    "    \"\"\"\n",
    "\n",
    "    # Étape 1 — Construction de D[i, j, t]\n",
    "    print(\"Construction du tenseur de distance pondérée D[i, j, t]...\")\n",
    "    distance_tensor = compute_distance_tensor(\n",
    "        distance_tensor=distance_tensor,\n",
    "        infra_tensor=infra_tensor,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Étape 2 — Distance maximale par type\n",
    "    print(\"Calcul des distances maximales par type d'infrastructure...\")\n",
    "    distance_max = compute_max_distance(distance_tensor)\n",
    "\n",
    "    # Étape 3 — Normalisation par Dmax[t]\n",
    "    print(\"Normalisation des distances...\")\n",
    "    distance_tensor = normalize_distance_tensor(\n",
    "        distance_tensor=distance_tensor,\n",
    "        distance_max=distance_max\n",
    "    )\n",
    "\n",
    "    # Étape 4 — Application de la décroissance exponentielle\n",
    "    print(\"Application de la fonction de décroissance exponentielle...\")\n",
    "    distance_tensor = apply_exponential_decay(distance_tensor)\n",
    "\n",
    "    # Étape 5 — Masquage des zones sans infrastructure\n",
    "    print(\"Restriction aux infrastructures réellement présentes...\")\n",
    "    distance_tensor = restrict_infra(\n",
    "        distance_tensor=distance_tensor,\n",
    "        infra_tensor=infra_tensor,\n",
    "        restrict=True\n",
    "    )\n",
    "\n",
    "    # Étape 6 — Calcul du dénominateur : somme pondérée (avec inversion)\n",
    "    print(\"Calcul du dénominateur (somme pondérée inversée)...\")\n",
    "    denominator = compute_weighted_sum(\n",
    "        population_tensor=population_tensor,\n",
    "        distance_tensor=distance_tensor,\n",
    "        apply_inverse=True,\n",
    "        transform=\"linear\",\n",
    "        a= 1/100000,\n",
    "        b=0.0\n",
    "    )\n",
    "\n",
    "    # Étape 7 — Calcul du numérateur : produit pondéré (avec carré de D)\n",
    "    print(\"Calcul du numérateur (produit pondéré)...\")\n",
    "    numerator = compute_weighted_product(\n",
    "        infra_tensor=infra_tensor,\n",
    "        distance_tensor=distance_tensor\n",
    "    )\n",
    "\n",
    "    # Libération explicite de la mémoire des tenseurs intermédiaires\n",
    "    del distance_tensor\n",
    "    del distance_max\n",
    "    gc.collect()  # Nettoyage mémoire Python\n",
    "\n",
    "    # Étape 8 — Division pour obtenir l'indice d'accessibilité\n",
    "    print(\"Calcul final de l'indice d'accessibilité...\")\n",
    "    index = compute_access_index(numerator, denominator)\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6abf346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_final_access_index( \n",
    "    distance_tensor: LabelledTensor,\n",
    "    population_tensor: LabelledTensor,\n",
    "    infra_tensor: LabelledTensor,\n",
    "    infra_tensor_th: LabelledTensor,\n",
    "    device: str = \"cpu\",\n",
    "    apply_minmax: bool = True\n",
    ") -> LabelledTensor:\n",
    "    \"\"\"\n",
    "    Calcule un indice d'accessibilité relatif ACCESS / ACCESS_TH, avec normalisation min-max optionnelle.\n",
    "\n",
    "    Ajoute une étape pour évaluer si chaque ACCESS_TH[i, t] ≥ ACCESS[i, t].\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    distance_tensor : LabelledTensor [i, j, t]\n",
    "        Tenseur des distances pondérées.\n",
    "    population_tensor : LabelledTensor [i]\n",
    "        Population par localisation.\n",
    "    infra_tensor : LabelledTensor [j, t]\n",
    "        Offre réelle d'infrastructure.\n",
    "    infra_tensor_th : LabelledTensor [j, t]\n",
    "        Offre théorique d'infrastructure.\n",
    "    device : str\n",
    "        Appareil de calcul (\"cpu\" ou \"cuda\").\n",
    "    apply_minmax : bool\n",
    "        Si True, applique une normalisation min-max par colonne t.\n",
    "\n",
    "    Retour\n",
    "    ------\n",
    "    LabelledTensor [i, t]\n",
    "        Indice d'accessibilité normalisé (ou brut).\n",
    "    \"\"\"\n",
    "\n",
    "    # Étape 1 : accessibilité réelle\n",
    "    access_real = compute_access_formula(\n",
    "        distance_tensor=distance_tensor,\n",
    "        population_tensor=population_tensor,\n",
    "        infra_tensor=infra_tensor,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Étape 2 : accessibilité théorique\n",
    "    access_th = compute_access_formula(\n",
    "        distance_tensor=distance_tensor,\n",
    "        population_tensor=population_tensor,\n",
    "        infra_tensor=infra_tensor_th,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Étape 3 : Évaluation ACCESS_TH ≥ ACCESS\n",
    "    comparison_mask = access_th.tensor >= access_real.tensor\n",
    "    count_true = comparison_mask.sum().item()\n",
    "    total_elements = comparison_mask.numel()\n",
    "    percentage = 100 * count_true / total_elements\n",
    "\n",
    "    # Logs détaillés\n",
    "    print(f\"[INFO] Elements where access_th ≥ access_real: {count_true} / {total_elements} \"\n",
    "        f\"({percentage:.2f}%)\")\n",
    "\n",
    "    # Étape 4 : ratio ACCESS / ACCESS_TH (sécurisé)\n",
    "    ratio_tensor = access_real.tensor / access_th.tensor.clamp(min=1e-8)\n",
    "\n",
    "    # Étape 5 : normalisation min-max par colonne t\n",
    "    if apply_minmax:\n",
    "        min_vals, _ = ratio_tensor.min(dim=0, keepdim=True)  # [1, t]\n",
    "        max_vals, _ = ratio_tensor.max(dim=0, keepdim=True)  # [1, t]\n",
    "        range_vals = (max_vals - min_vals).clamp(min=1e-8)\n",
    "        normalized = (ratio_tensor - min_vals) / range_vals\n",
    "    else:\n",
    "        normalized = ratio_tensor\n",
    "\n",
    "    return LabelledTensor(\n",
    "        normalized,\n",
    "        dim_labels=access_real.dim_labels,\n",
    "        index_to_label=access_real.index_to_label\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2d93716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construction du tenseur de distance pondérée D[i, j, t]...\n",
      "Calcul des distances maximales par type d'infrastructure...\n",
      "Normalisation des distances...\n",
      "Application de la fonction de décroissance exponentielle...\n",
      "Restriction aux infrastructures réellement présentes...\n",
      "Calcul du dénominateur (somme pondérée inversée)...\n",
      "Calcul du numérateur (produit pondéré)...\n",
      "Calcul final de l'indice d'accessibilité...\n",
      "Construction du tenseur de distance pondérée D[i, j, t]...\n",
      "Calcul des distances maximales par type d'infrastructure...\n",
      "Normalisation des distances...\n",
      "Application de la fonction de décroissance exponentielle...\n",
      "Restriction aux infrastructures réellement présentes...\n",
      "Calcul du dénominateur (somme pondérée inversée)...\n",
      "Calcul du numérateur (produit pondéré)...\n",
      "Calcul final de l'indice d'accessibilité...\n",
      "[INFO] Elements where access_th ≥ access_real: 112486 / 125940 (89.32%)\n"
     ]
    }
   ],
   "source": [
    "index = compute_final_access_index(\n",
    "    distance_tensor=distance_tensor,\n",
    "    population_tensor=population_tensor,\n",
    "    infra_tensor=infra_tensor,\n",
    "    infra_tensor_th=infra_tensor_th,\n",
    "    device=\"cuda\",\n",
    "    apply_minmax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dcb570b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8_396, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Localité</th><th>06</th><th>06001</th><th>060010001</th><th>060010002</th><th>060010003</th><th>060010004</th><th>06002</th><th>060020001</th><th>060020002</th><th>060020004</th><th>06003</th><th>060030001</th><th>060030002</th><th>060030004</th><th>060030005</th></tr><tr><td>str</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>&quot;010020201001&quot;</td><td>0.978221</td><td>0.943222</td><td>0.041562</td><td>0.738847</td><td>0.141172</td><td>0.021895</td><td>0.020847</td><td>0.018287</td><td>0.002406</td><td>0.000135</td><td>0.014027</td><td>0.000139</td><td>0.013352</td><td>0.000051</td><td>0.000493</td></tr><tr><td>&quot;010020201003&quot;</td><td>0.980008</td><td>0.944971</td><td>0.041686</td><td>0.740592</td><td>0.141154</td><td>0.021564</td><td>0.0208</td><td>0.018244</td><td>0.002396</td><td>0.000135</td><td>0.014064</td><td>0.000135</td><td>0.013383</td><td>0.000048</td><td>0.000499</td></tr><tr><td>&quot;010020201004&quot;</td><td>0.980557</td><td>0.94551</td><td>0.041639</td><td>0.741162</td><td>0.141363</td><td>0.021536</td><td>0.020815</td><td>0.018248</td><td>0.002412</td><td>0.000137</td><td>0.014104</td><td>0.000137</td><td>0.013425</td><td>0.000051</td><td>0.000499</td></tr><tr><td>&quot;010020201005&quot;</td><td>0.980784</td><td>0.945736</td><td>0.04164</td><td>0.741412</td><td>0.141415</td><td>0.021544</td><td>0.020827</td><td>0.018257</td><td>0.002417</td><td>0.000137</td><td>0.014115</td><td>0.000137</td><td>0.013437</td><td>0.000051</td><td>0.000501</td></tr><tr><td>&quot;010020201007&quot;</td><td>0.982851</td><td>0.947727</td><td>0.041787</td><td>0.743161</td><td>0.141583</td><td>0.021387</td><td>0.020865</td><td>0.018298</td><td>0.002413</td><td>0.000136</td><td>0.014139</td><td>0.000136</td><td>0.013457</td><td>0.00005</td><td>0.000506</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;330840498007&quot;</td><td>1.020363</td><td>0.984201</td><td>0.042069</td><td>0.782238</td><td>0.142556</td><td>0.017126</td><td>0.020652</td><td>0.017774</td><td>0.002797</td><td>0.000082</td><td>0.015457</td><td>0.000098</td><td>0.014806</td><td>0.000076</td><td>0.000493</td></tr><tr><td>&quot;330840498008&quot;</td><td>1.017735</td><td>0.981608</td><td>0.041988</td><td>0.780164</td><td>0.142469</td><td>0.017088</td><td>0.020724</td><td>0.017832</td><td>0.002812</td><td>0.000098</td><td>0.015445</td><td>0.000098</td><td>0.014798</td><td>0.000078</td><td>0.000499</td></tr><tr><td>&quot;330840498009&quot;</td><td>1.006459</td><td>0.970501</td><td>0.041876</td><td>0.769085</td><td>0.140941</td><td>0.018386</td><td>0.02088</td><td>0.018013</td><td>0.002758</td><td>0.000108</td><td>0.014989</td><td>0.000108</td><td>0.014349</td><td>0.000065</td><td>0.000469</td></tr><tr><td>&quot;330840498010&quot;</td><td>1.00654</td><td>0.970585</td><td>0.041878</td><td>0.769177</td><td>0.140972</td><td>0.018396</td><td>0.020887</td><td>0.018019</td><td>0.002761</td><td>0.000108</td><td>0.014994</td><td>0.000108</td><td>0.014354</td><td>0.000065</td><td>0.00047</td></tr><tr><td>&quot;330840498011&quot;</td><td>1.024546</td><td>0.988442</td><td>0.041863</td><td>0.787046</td><td>0.143365</td><td>0.015593</td><td>0.020438</td><td>0.017559</td><td>0.002792</td><td>0.000083</td><td>0.015557</td><td>0.000081</td><td>0.014916</td><td>0.000078</td><td>0.000489</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8_396, 16)\n",
       "┌────────────┬──────────┬──────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ Localité   ┆ 06       ┆ 06001    ┆ 060010001 ┆ … ┆ 060030001 ┆ 060030002 ┆ 060030004 ┆ 060030005 │\n",
       "│ ---        ┆ ---      ┆ ---      ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ str        ┆ f32      ┆ f32      ┆ f32       ┆   ┆ f32       ┆ f32       ┆ f32       ┆ f32       │\n",
       "╞════════════╪══════════╪══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0100202010 ┆ 0.978221 ┆ 0.943222 ┆ 0.041562  ┆ … ┆ 0.000139  ┆ 0.013352  ┆ 0.000051  ┆ 0.000493  │\n",
       "│ 01         ┆          ┆          ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 0100202010 ┆ 0.980008 ┆ 0.944971 ┆ 0.041686  ┆ … ┆ 0.000135  ┆ 0.013383  ┆ 0.000048  ┆ 0.000499  │\n",
       "│ 03         ┆          ┆          ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 0100202010 ┆ 0.980557 ┆ 0.94551  ┆ 0.041639  ┆ … ┆ 0.000137  ┆ 0.013425  ┆ 0.000051  ┆ 0.000499  │\n",
       "│ 04         ┆          ┆          ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 0100202010 ┆ 0.980784 ┆ 0.945736 ┆ 0.04164   ┆ … ┆ 0.000137  ┆ 0.013437  ┆ 0.000051  ┆ 0.000501  │\n",
       "│ 05         ┆          ┆          ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 0100202010 ┆ 0.982851 ┆ 0.947727 ┆ 0.041787  ┆ … ┆ 0.000136  ┆ 0.013457  ┆ 0.00005   ┆ 0.000506  │\n",
       "│ 07         ┆          ┆          ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆ …        ┆ …        ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 3308404980 ┆ 1.020363 ┆ 0.984201 ┆ 0.042069  ┆ … ┆ 0.000098  ┆ 0.014806  ┆ 0.000076  ┆ 0.000493  │\n",
       "│ 07         ┆          ┆          ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 3308404980 ┆ 1.017735 ┆ 0.981608 ┆ 0.041988  ┆ … ┆ 0.000098  ┆ 0.014798  ┆ 0.000078  ┆ 0.000499  │\n",
       "│ 08         ┆          ┆          ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 3308404980 ┆ 1.006459 ┆ 0.970501 ┆ 0.041876  ┆ … ┆ 0.000108  ┆ 0.014349  ┆ 0.000065  ┆ 0.000469  │\n",
       "│ 09         ┆          ┆          ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 3308404980 ┆ 1.00654  ┆ 0.970585 ┆ 0.041878  ┆ … ┆ 0.000108  ┆ 0.014354  ┆ 0.000065  ┆ 0.00047   │\n",
       "│ 10         ┆          ┆          ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 3308404980 ┆ 1.024546 ┆ 0.988442 ┆ 0.041863  ┆ … ┆ 0.000081  ┆ 0.014916  ┆ 0.000078  ┆ 0.000489  │\n",
       "│ 11         ┆          ┆          ┆           ┆   ┆           ┆           ┆           ┆           │\n",
       "└────────────┴──────────┴──────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.to_dataframe(\n",
    "    index_dim=\"i\",\n",
    "    column_dim=\"t\",\n",
    "    index_name=\"Localité\",\n",
    "    value_name=\"Indice d'accessibilité\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55125b9e",
   "metadata": {},
   "source": [
    "#### **SIMULATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85568ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to update the time-distance matrix\n",
    "def update_mat_dist_temps(troncons, ancien_type, nouveau_type, data_type):\n",
    "    # Load the old itinerary matrix for the old type\n",
    "    path_old_matrix = os.path.join(ITINERAIRES_DIR, f\"Itineraire_Matrix_{ancien_type.upper()}\")\n",
    "    Mat_Dist_Temps = pl.from_pandas(Mat_Dist_Temps_0)\n",
    "\n",
    "    pass_var = \"vehicule_lg\"*(data_type==\"en ligne\") + \"vehicule_p\"*(data_type==\"terrain\") \n",
    "\n",
    "    itineraire_bin = pl.DataFrame()\n",
    "\n",
    "\n",
    "    # Loop through the files in the directory\n",
    "    for file in os.listdir(path_old_matrix):\n",
    "        print(file)\n",
    "\n",
    "        # Load the parquet file into a Polars DataFrame\n",
    "        locals()[\"%s\" % file] = pl.read_parquet(os.path.join(path_old_matrix, file))\n",
    "\n",
    "        # Sort by \"Idloc_start\"\n",
    "        locals()[\"%s\" % file] = locals()[\"%s\" % file].sort(\"Idloc_start\")\n",
    "        locals()[\"%s\" % file] = locals()[\"%s\" % file].with_columns([\n",
    "                                    pl.col(col).fill_null(\"\").alias(col)\n",
    "                                    for col in locals()[\"%s\" % file].columns\n",
    "                                    ])\n",
    "\n",
    "        # interm_matrix = pl.DataFrame()\n",
    "\n",
    "        agregated_matrix = locals()[\"%s\" % file].with_columns([\n",
    "            pl.lit(0).alias(col) if col != \"Idloc_start\" else pl.col(col)\n",
    "            for col in locals()[\"%s\" % file].columns\n",
    "        ])\n",
    "\n",
    "        # Loop through each column of the current DataFrame\n",
    "        for segment in troncons:\n",
    "\n",
    "            long = route_loc[route_loc['gid']==int(segment)]['length'].values[0]\n",
    "            coef_old = route_loc[route_loc['gid']==int(segment)][pass_var].values[0]\n",
    "            coef_new = route_loc[route_loc['stat_voie']==nouveau_type.upper()][pass_var].values[0]\n",
    "        \n",
    "            time_saved = (coef_new - coef_old) * long\n",
    "\n",
    "            print(f\"time saved for {segment}: \", time_saved)\n",
    "\n",
    "            interm_matrix = locals()[\"%s\" % file].select([\n",
    "                pl.col(column).map_elements(lambda x: binary(str(x), segment)).alias(column)\n",
    "                if column != \"Idloc_start\" else pl.col(column) for column in \n",
    "                locals()[\"%s\" % file].columns])\n",
    "\n",
    "            interm_matrix[interm_matrix.columns[1:]] = interm_matrix[interm_matrix.columns[1:]]\\\n",
    "                                                       .select(pl.col(\"*\").cast(pl.Int64))\n",
    "\n",
    "            agregated_matrix[agregated_matrix.columns[1:]] += interm_matrix[interm_matrix.columns[1:]]\\\n",
    "                                                       .select(pl.all() * time_saved)\n",
    "            \n",
    "        # Concatenate the intermediate matrix with the global binary itinerary matrix\n",
    "        itineraire_bin = pl.concat([itineraire_bin, agregated_matrix], \n",
    "                                   how=\"vertical\")\n",
    "\n",
    "    mdt_combined = Mat_Dist_Temps.join(itineraire_bin, on=\"Idloc_start\", how=\"left\")\n",
    "    updated_columns = [(pl.col(col) + pl.col(f\"{col}_right\").fill_null(0)).alias(col) \n",
    "                       for col in Mat_Dist_Temps.columns if col != \"Idloc_start\"]\n",
    "    \n",
    "    mdt_combined = mdt_combined.with_columns(updated_columns)\\\n",
    "                               .select(Mat_Dist_Temps.columns)\n",
    "    \n",
    "    return mdt_combined.to_pandas()\n",
    "\n",
    "\n",
    "def simulation_voie(secteur, troncons, ancien_type, nouveau_type, data_type=\"terrain\"):\n",
    "\n",
    "    Mat_Dist_Temps = update_mat_dist_temps(troncons, ancien_type, nouveau_type, data_type)\n",
    "    print(\"Mat_Dist_Temps OK\")\n",
    "    print(Mat_Dist_Temps.shape)\n",
    "    accessibilite = compute_accessibility_index(Mat_Dist_Temps, secteur, list_loc, data_type)\n",
    "    print(\"Accessibilte OK\")\n",
    "    eloig = eloignement(Mat_Dist_Temps, secteur, list_loc, data_type)\n",
    "    print(\"Eloignement OK\")\n",
    "    accessibilite = accessibilite.merge(list_loc[[\"idloc_iai\",\"NomLoc\",\"NomReg\"]],\n",
    "                                         on=\"idloc_iai\",how=\"outer\")\\\n",
    "                                  .sort_values(by=[\"idloc_iai\"])\n",
    "    print(\"Access format OK\")\n",
    "    eloig = eloig.merge(list_loc[[\"idloc_iai\",\"NomLoc\",\"NomReg\"]],\n",
    "                                        on=\"idloc_iai\",how=\"outer\")\\\n",
    "                                 .sort_values(by=[\"idloc_iai\"])\n",
    "    print(\"Eloignement format OK\")\n",
    "\n",
    "    return accessibilite, eloig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
